# (PART) Trabajar con datos {-}

# Trabajar con datos {#cap-datos}

## Resumen

En este capítulo:

- Vamos a revisar algunas de las principales operaciones que tenemos que realizar con bases de datos para ordenarlas y para hacer algunos análisis. 
- Aprenderemos cómo realizar subconjuntos de datos, lidiar con datos no disponibles (`NA`), agrupar observaciones y unir bases de datos. 
- Familiarizarnos con las herramientas contenidas en la metalibrería `tidyverse`, especialmente las librerías `dplyr` y `tidyr`.

**Principales conceptos**: hacer subconjuntos de datos; agrupar observaciones; unir bases de datos relacionales.

**Funciones clave**: `filter()`; `select()`; `group_by()`; `summarize()`; `left_join()`.

### Librerías

Vamos a utilizar las siguientes librerías:

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(gapminder) # datos para ejercicios
library(readxl) # cargar archivos .xlsx
library(writexl) # guardar archivos .xlsx
library(knitr) # tablas en RMarkdown
library(haven) # cargar archivos .dta
library(janitor) # limpiar nombres de variables
library(countrycode) # codigos de pais para unir bases de datos
```

```{r, include=FALSE}
theme_set(theme_light())
```

### Datos

Debemos descargar los siguientes archivos de datos y guardarlos en la carpeta `/data` de nuestro proyecto:

- Polity IV: [link](https://github.com/josefortou/lab-book/blob/master/data/p4v2017.xls). Para descargar, hacer click en "Download".
- Database of Political Institutions, 2017: [link](https://github.com/josefortou/lab-book/blob/master/data/DPI2017.dta). Para descargar, hacer click en "Download".
- Homicidios en Medellín: [link](https://github.com/josefortou/lab-book/blob/master/data/mde_homicidio.csv). Para descargar, hacer click derecho, "Guardar como...".
- Comunas de Medellín: [link](https://github.com/josefortou/lab-book/blob/master/data/mde_df.csv). Para descargar, hacer click derecho, "Guardar como...".

## Cargar bases de datos

Para efectos de este curso, aunque también en ciencias sociales en general, una *base de datos* es una recopilación de información en formato rectangular, con tres elementos esenciales:

- Filas que representan casos u observaciones.
- Columnas que representan variables o características de esos casos. 
- Celdas en la intersección de filas y columnas y que contienen información (valores) sobre características de cada caso. 

La mayor parte de los análisis estadísticos en ciencias sociales se realizan al hacer operaciones o aplicar funciones a bases de datos de este tipo.

Como mencionamos anteriormente, vamos a trabajar con distintas librerías del `tidyverse` para trabajar con bases de datos rectangulares. Estaremos utilizando varias funciones de las librerías `dplyr` y `tidyr` para transformar bases de datos y organizarlos de tal manera que podamos realizar análisis de datos exploratorios.

### Bases de datos incluidas en R

R incluye unas cuantas bases de datos que podemos usar sin descargar primero. Ya están incluidas y disponibles en `datasets`, una librería que viene "pre-cargada" en cada sesión de R. La lista es extensa e incluye:

- `AirPassengers`: viajeros mensuales en aerolíneas americanas, 1949-1960.
- `Titanic`: sobrevivientes del hundimiento del *RMS Titanic*.
- `mtcars`: tests de carros de la revista *MotorTrend*. 
- `airquality`: calidad del aire en New York.
- `iris`: especies de plantas _iris_.

Otras bases de datos vienen en librerías que cargamos nosotros mismos. Por ejemplo, como ya cargamos `tidyverse` en esta sesión, podemos mirar `economics`, una base de datos macroeconómicos básicos de Estados Unidos:

```{r}
economics
```

Esta base de datos contiene datos en serie de tiempo -mes a mes- del desempleo en Estados Unidos, de julio de 1967 a abril de 2015 (la columna `unemploy`). Son en total `r nrow(economics)` observaciones. ¿Cuál ha sido el comportamiento de este indicador en este periodo? Utilicemos `ggplot2` para visualizar esta serie de tiempo. 

Calculamos la tasa de desempleo dentro de la misma función (`unemploy/pop`) y graficamos el resultado a través del tiempo. Podemos observar claramente un pico durante la "Gran Recesión" de 2007-2009:

```{r}
# datos y variables a usar
ggplot(data = economics, aes(x = date, y = unemploy/pop)) + 
  # tipo de gráfica: línea
  geom_line(color = "darkred") 
```

Otras librerías vienen con sus propias bases de datos. Aquí cargamos datos de la librería `gapminder`, que se deriva del trabajo educativo de la [Gapminder Foundation](https://www.gapminder.org/). Esta librería contiene una base de datos también llamada `gapminder`. Veamos 10 observaciones aleatorias de esta base de datos, usando la función `sample_n()`:

```{r}
sample_n(gapminder, size = 10)
```

Vemos que hay información sobre expectativa de vida al nacer (`lifeExp`) y el PIB per cápita (`gdpPercap`) para `r nrow(distinct(gapminder, country))` países en intervalos de 5 años. ¿Cuál es la relación entre estas dos variables? Podemos hacer una gráfica de dispersión:

```{r}
# datos y variables
ggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) + 
  # tipo de gráfica, puntos con con opacidad 50%
  geom_point(alpha = 0.5, color = "darkblue") 
```

Parece que hay una relación positiva, pero no estrictamente lineal. Más bien, puede ser de tipo logarítmico, indicando rendimientos decrecientes. Nuevamente, podemos hacer la transformación de la variable `gdpPercap` directamente en la función `ggplot()` usando `log()`:

```{r}
# datos y variables
ggplot(data = gapminder, aes(x = log(gdpPercap), y = lifeExp)) + 
  # tipo de gráfica, puntos con con opacidad 50%
  geom_point(alpha = 0.5, color = "darkgreen")
```

Por otro lado, si nos interesa ver la frecuencia de una variable categórica, podríamos contar cuántas observaciones (países-año) hay por continente usando la función `count()`, algo similar a lo que hicimos con `table()` en capítulos anteriores:

```{r}
count(gapminder, continent)
```

### Archivos locales

Es más frecuente que estemos interesados en trabajar con otros datos que recogimos o descargamos de otras fuentes. Para esto, debemos tener el archivo de datos ubicado en una carpeta en nuestro equipo, idealmente dentro del proyecto en el que estamos trabajando en RStudio. Recordemos que en este libro, vamos a utilizar la carpeta o directorio `\data` para esto.[^1] Si queremos ver qué archivos ya están en una carpeta, podemos usar la función `list.files()`, dándole la dirección de la carpeta:

[^1]: Si estamos en RStudio Cloud, debemos empezar por subirlos y ubicarlos en una carpeta dentro del proyecto. Vamos al panel inferior derecho, pestaña `Files`, click en `Upload` y seguimos las indicaciones.

```{r}
list.files("data/")
```

Vemos que en esta carpeta ya hay varios archivos y de varios tipos. Dependiendo del tipo de archivo (Excel, CSV, datos de Stata, etc.) utilizamos una función distinta. Las librerías `readr`, `readxl` y `haven` del `tidyverse` son nuestras amigas para este tipo de trabajos.

Veamos esto en acción. Carguemos los datos del proyecto [Polity IV](http://www.systemicpeace.org/inscrdata.html) sobre democracia institucional, un conjunto de datos muy utilizado en ciencia política, pero que ha recibido críticas en los últimos años. Como los datos están en formato Excel 97-03 (el archivo tiene extensión `.xls`), usamos la función `read_excel()` de la librería `readxl` y le asignamos un nombre al objeto (los datos) que estamos creando de la siguiente manera:[^2] 

[^2]: También los podemos cargar usando los menús del programa; el asistente para cargar datos en RStudio (pestaña `Environment`, opción `Import Dataset`) es bastante bueno y nos arroja código que después debemos copiar en un Rmarkdown o R script para replicar nuestros análisis. 

```{r}
polity4 <- read_excel("data/p4v2017.xls")
```

Para confirmar que todo está bien, revisemos las primeras filas del objeto que creamos imprimiendo a la consola el objeto:

```{r}
polity4
```

Parece que todo está bien. Miremos la distribución de la variable `polity2`, el popular indicador combinado de democracia de Polity IV. Aquí volvemos a usar la librería `ggplot2` en vez de las funciones de `base`, como `plot()` y `barplot()`:

```{r}
# datos y variables
ggplot(data = polity4, aes(x = polity2)) + 
  # tipo de gráfica y ancho de las barras
  geom_histogram(binwidth = 1)
```

Vemos que hay más casos de democracia (valores altos del indicador) y de autocracia (valores bajos) que anocracias (valores medios).

### Descarga web

Por último, carguemos unos datos directamente de la web, sin tener que descargarlos primero. El *Uppsala Conflict Data Program* (UCDP) tiene una de las bases de datos más completas sobre conflicto armado y está fácilmente disponible para su uso: el *Armed Conflict Dataset*. Con `read_csv()` podemos darle a R el URL del archivo y cargarlo como un objeto nuevo. Necesitamos una conexión a internet activa y se puede demorar unos segundos más. Lo hacemos de la siguiente manera:

```{r, cache = TRUE, message = FALSE}
ucdp <- read_csv("http://ucdp.uu.se/downloads/ucdpprio/ucdp-prio-acd-201.csv")
```

UCDP distingue entre cuatro tipos de conflicto armado: interestatal, extraestatal, interno e interno internacionalizado. ¿Cuántos casos hay de cada tipo en la base de datos? Si leemos el libro de códigos de la base de datos, vemos que la variable `type_of_conflict` toma cuatro valores: 1 (inter-), 2 (extra-), 3 (intra-) y 4 (intra- internacionalizado). La prevalencia global de los conflictos armados internos es clara:

```{r}
# datos y variables
ggplot(ucdp, aes(type_of_conflict)) +
  # tipo de gráfica
  geom_bar()
```

Pero esto no siempre ha sido así. Con unas líneas de código adicionales, podemos ver los cambios en el tiempo en el tipo de conflicto armado predominante a nivel global. Primero, resumimos los datos, contando (con `count()`) el número de conflictos por año y tipo de conflicto:

```{r}
conflictos <- count(ucdp, year, type_of_conflict)
conflictos
```

Ahora, utilizamos esa tabla de datos resumidos para ver los cambios temporales, especificando que queremos una gráfica de barras con un color para cada tipo de conflicto:

```{r}
ggplot(conflictos, aes(year, n, fill = factor(type_of_conflict))) +
  # tipo de gráfica
  geom_col()
```

Con base en estos datos, podemos concluir que los conflictos armados internos (internacionalizados o no) se han vuelto cada vez más frecuentes, especialmente a partir del fin de la guerra fría, mientras que los conflictos entre estados son cada vez menos comunes.

Podemos hacer otras operaciones más allá de cargar datos, contar casos y hacer gráficas de estas frecuencias. A continuación, vamos a utilizar las principales herramientas del `tidyverse` para seleccionar, transformar . Miremos cada una de estas operaciones. Al final, veremos que, en conjunto, ofrecen una caja de herramientas potente --y necesaria-- para el analista de datos políticos.

## Seleccionar datos

En ocasiones, una base de datos va a tener más filas y columnas de las que necesitamos, dada una teoría y un diseño de investigación. Para esto, con frecuencia nos vemos en la necesidad de:

- Seleccionar filas (observaciones o casos).
- Organizar y ordenar estas observaciones.
- Seleccionar columnas (variables).

A continuación, revisamos estas operaciones.
  
## Seleccionar filas: `filter()`

A veces no necesitamos todas las filas en una base de datos, sino que queremos concentrarnos en algunas observaciones o casos que creemos son relevantes. Por ejemplo, puede que solo queramos estudiar los países más pobres según los datos de `gapminder()` o solo las guerras civiles de UCDP. Para esto, la principal función que usamos es `filter()`.

### Seleccionar filas por condiciones

El tipo de selección más sencilla consiste en seleccionar condicionalmente filas usando evaluaciones lógicas. Por ejemplo, puede que nos interese ver solamente las observaciones para el año 2007 de la base de datos de `gapminder`, para lo cual usamos `filter()` en conjunción con el operador `==` (estrictamente igual a). A continuación, seleccionamos las filas que tienen *exactamente* el valor 2007 en la variable `year`:

```{r}
filter(gapminder, year == 2007)
```

Así mismo, podemos hacer una selección según valores de más de una variable. Nos valemos de otros operadores, como `&` y `|`. El operador `&` es el booleano "y" (AND). Con `&` podemos seleccionar observaciones que cumplan dos condiciones simultáneamente (observaciones del año 2007 y expectativa de vida por encima de los 60 años):

```{r}
filter(gapminder, year == 2007 & lifeExp > 60)
```

Simplificando, `filter()` nos permite reemplazar los `&` por `,`:

```{r}
filter(gapminder, year == 2007, lifeExp > 60)
```

Mientras, el operador `|` es el booleano "o" (OR). Aquí, seleccionamos observaciones que cumplan una condición o la otra (el año 2007 *o* el año 1997):

```{r}
filter(gapminder, year == 2007 | year == 1997)
```

Si tenemos muchas condiciones de tipo OR (`|`) usamos el operador `%in%` seguido de una lista de condiciones concatenadas con `c()` para simplificar el código, de esta manera:

```{r}
# guardamos la muestra como un objeto
eurasia <- filter(gapminder, continent %in% c("Europe", "Asia"))

# revisamos con una muestra de 5 observaciones aleatorias
sample_n(eurasia, 5) 
```

Dentro de `filter()` podemos utilizar estos operadores, así como otros como `<`, `<=`, `>` y `>=` e incluso funciones como `max()` o `mean()`. Por ejemplo, a continuación seleccionamos solo los casos que tengan una expectativa de vida mayor o igual a la media global de esa variable:

```{r}
filter(gapminder, lifeExp >= mean(lifeExp, na.rm = TRUE))
```

A veces, es más fácil pedirle a R que seleccione los datos que *no* cumplen una condición. Para eso está el operador `!=` (no es igual a):

```{r}
filter(gapminder, continent != "Asia")
```

Dos funciones adicionales -`top_n()` y `top_frac`- nos permiten seleccionar las primeras observaciones cuando ordenamos los datos según una variable, como cuando hacemos "Sort" u "Ordenar" en un programa como Excel. Por ejemplo, aquí seleccionamos el "top 5" de países según PIB per cápita:

```{r}
top_n(gapminder, 5, gdpPercap)
```

Y aquí los 5 peores:

```{r}
top_n(gapminder, -5, gdpPercap)
```

Veamos el top 99.5% de los países con mayor expectativa de vida al nacer:

```{r}
top_frac(gapminder, 0.005, lifeExp)
```

Finalmente, podemos guardar los resultados de esta selección como un objeto, para seguir trabajando con este subconjunto de los datos. Esto es altamente recomendable, para no tener que repetir el mismo código cada vez que queremos trabajar con un subconjunto de datos. Veamos dos ejemplos:

```{r}
gapminder_reciente <- filter(gapminder, year %in% c(1997, 2002, 2007))
gapminder_america <- filter(gapminder, continent == "Americas")
```

Además, si guardamos el objeto como un archivo `.csv` o `.xlsx` por ejemplo y lo cargamos después, podemos "saltarnos" muchas líneas de código en una sesión futura o en otro proyecto. Si queremos guardar un archivo de Excel, usamos la función `write_xlsx()` de la librería `writexl`, especificando la carpeta de destino y el nombre del nuevo archivo:

```{r, eval = FALSE}
write_xlsx(gapminder_america, "data/gapminder_america.xlsx")
```

Exportar datos en formato Excel de esta manera nos permite utilizarlos en ese programa o compartirlo con colegas o un público que no necesariamente tiene conocimiento de R. Sin embargo, si pensamos seguir trabajando en R, es recomendable guardar los datos como archivos de tipo RDS o CSV. Hacemos esto de la siguiente manera, usando funciones análogas de la librería `readr`, incluida en el `tidyverse`:

```{r, eval = FALSE}
# guardar como archivo de datos de R
write_rds(gapminder_america, "data/gapminder_america.rds")
# guardar como archivo de datos CSV
write_csv(gapminder_america, "data/gapminder_america.csv")
```

### Seleccionar filas por posición

Si con `filter()` podemos usar valores de variables como criterios de selección, con `slice()` podemos seleccionar un número arbitrario de observaciones según la posición de la fila en la base de datos. Por ejemplo, si queremos solo la observación o fila número 100:

```{r}
slice(gapminder, 100)
```

O las observaciones de la 55 a la 65 de una base de datos:

```{r}
slice(gapminder, 55:65)
```

Quizás la última observación, usando la función `n()`:

```{r}
slice(gapminder, n())
```

O todas las filas, menos de la octava observación hasta la última:

```{r}
slice(gapminder, -8:-n())
```

En cierto sentido, `slice()` es similar a `head()` y `tail()`, las cuales usamos para explorar las primeras y últimas filas de una base de datos: 

```{r}
tail(gapminder)
```

La diferencia es que estas dos últimas funciones no pueden seleccionar filas en la mitad de una base de datos.

## Reordenar filas: `arrange()`

Es probable que todos estemos familiarizados con la opción "Ordenar" (o "Sort") en Excel y programas similares: nos permite ordenar datos de mayor a menor (o menor a mayor) según los valores de una variables. En el `tidyverse`, tenemos `arrange()`, una función que cambia el orden de las filas. En vez del orden alfabético por defecto de `gapminder`, organicemos la base de datos por PIB per cápita, de menor a mayor:

```{r}
arrange(gapminder, gdpPercap)
```

Podemos utilizar más de una variable para ordenar los datos:

```{r}
arrange(gapminder, country, year)
```

Si queremos que este nuevo orden sea permanente, debemos crear un objeto nuevo o reescribir el original, como mostramos a continuación:

```{r}
gapminder <- arrange(gapminder, country, year)
```

Por último, podemos ordenar los datos de manera descendente usando el operador `-`. Aquí, ordenamos los datos por PIB per cápita, pero de mayor a menor:

```{r}
arrange(gapminder, -gdpPercap)
```

## Seleccionar variables: `select()`

Ya vimos cómo seleccionar filas u observaciones (casos). Esta es una herramienta indispensable para asegurarnos que nuestros análisis correspondan a la muestra o muestras que más nos interesan, dados elementos como nuestra pregunta, teoría y diseño.

Por otro lado, en ocasiones no necesitamos todas las columnas que están incluidas een una base de datos. Por ejemplo, solo nos interesan las variables económicas y no las demográficas. En otras palabras, queremos eliminar unas columnas y mantener otras. Para esto, usamos la función `select()`. Seleccionemos solo tres columnas de `gapminder`:

```{r}
select(gapminder, country, year, gdpPercap)
```

Podemos usar el operador `:` para seleccionar un rango de variables, según el orden en que aparecen en la base de datos (aquí, *desde* `year` *hasta* `pop`):

```{r}
select(gapminder, year:pop)
```

De manera análoga a `filter()`, podemos seleccionar todo excepto ciertas variables. Aquí, seleccionamos todas menos `continent` y `pop`:

```{r}
select(gapminder, -continent, -pop)
```

La función `select()` tiene unas funciones hermanas que le agregan flexibilidad y expanden lo que podemos hacer con ella. Por ejemplo, con `where()` podemos seleccionar variables que cumplen una condición. En el siguiente caso, selecionamos solo las columnas numéricas (según su clase en R):

```{r}
select(gapminder, where(is.numeric))
```

O podríamos seleccionar solo las columnas definidas como factores en R (variables categóricas con niveles o categorías definidas):

```{r}
select(gapminder, where(is.factor))
```

Usando `starts_with`, podemos quedarnos solo con las columnas cuyo nombre comienza por una letra o una expresión en específico. Esto puede ser útil cuando tenemos columnas con nombres como `indicador_a`, `indicador_b`, `indicador_c`, etc. y queremos seleccionarlas. Por ejemplo, seleccionemos columnas que empiezan por "c":

```{r}
select(gapminder, starts_with("c"))
```

La función `ends_with()` hace lo opuesto, busca columnas que terminan con ciertos patrones o expresiones:

```{r}
select(gapminder, ends_with("p"))
```

Mientras, `contains()` busca columnas que tengan ciertos caracteres, sea al principio, final o en la mitad:

```{r}
select(gapminder, contains("Exp"))
```

### Renombrar columnas: `rename()`

Podemos renombrar columnas directamente dentro de `select()`, pero esto descarta de la base de datos todas las variables no renombradas explícitamente:

```{r}
select(gapminder, pib_percap = gdpPercap)
```

En cambio, `rename()` nos permite renombrar variables y además mantener las demás:

```{r}
rename(
  gapminder, 
  # nombre_nuevo = nombre_viejo
  continente = continent, ano = year, exp_vida = lifeExp, 
  pob = pop, pib_percap = gdpPercap
)
```

## Transformar datos

Una vez tenemos una base de datos cargada en R (o sea, que está definido como un objeto en el `Environment`) y opcionalmente hemos seleccionado un subconjunto de interés, queremos *hacer algo* con esos datos. Usualmente, ese algo implica *transformarlos*. Hay muchas formas de transformar datos en R. Algunas de las principales son:

- Computar nuevas variables o transformar las existentes.
- Resumir datos por grupos.
- Trabajar con datos no disponibles (`NA`).

A continuación, revisamos estas operaciones esenciales.

## Crear y transformar variables: `mutate()`

Las bases de datos no siempre tienen todas las variables que necesitamos. Pero pueden tener la información necesaria para que las creemos nosotros mismos. `mutate()` es la principal función que usamos para crear variables o modificar variables existentes. `mutate()` siempre adiciona columnas nuevas a la base de datos, pero -como veremos- si queremos que queden grabadas al objeto, debemos usar el operador de asignación `<-`. 

Como ejemplo, tomemos `gapminder`. Tenemos información sobre PIB per cápita (`gdpPercap`), pero en realidad queremos el PIB. Esa columna no existe en los datos, pero tenemos la información suficiente para construirla. El PIB per cápita se define como $\frac{PIB}{población}$, así que si utilizamos la variable `pop` tenemos lo necesario para calcular el PIB:

```{r}
mutate(gapminder, gdp = gdpPercap*pop)
```

Si solo queremos mantener las variables creadas (y descartar las originales), usamos `transmute()`, pero rara vez queremos deshacernos de todo:

```{r}
transmute(gapminder, gdp = gdpPercap*pop)
```

Además, podemos usar muchas otras funciones, como `log()`, para crear nuevas variables. Por ejemplo, si queremos el logaritmo del PIB per cápita:

```{r}
mutate(gapminder, gdpPercap_log = log(gdpPercap))
```

Usualmente, queremos que las variables recién creadas *permanezcan y se vuelvan parte de la base de datos* en R. Entonces, debemos reescribir el objeto (o crear uno nuevo) usando el operador de asignación `<-`. Breve recordatorio: si usamos el mismo nombre del objeto original, lo reescribimos, pero si usamos un nuevo nombre, creamos un objeto adicional. Veamos cómo reescribir `gapminder` para agregar unas nuevas variables:

```{r}
gapminder <- mutate(
  gapminder, 
  gdp = gdpPercap*pop, 
  gdp_log = log(gdp), 
  gdpPercap_log = log(gdpPercap)
)
```

Inspeccionemos el resultado para confirmar que las nuevas columnas ahora sí quedaron guardadas en el objeto:

```{r}
select(gapminder, country, year, gdp_log, gdpPercap_log)
```

Otro ejemplo útil: podemos calcular valores acumulados, rezagados y adelantados de una variable. En el caso de una base de datos donde la unidad de análisis es el país-año (o sea, cada fila tiene información para un país en un año), esto nos permite calcular los valores del año anterior. Para ilustrar este procedimiento, hagamos un pequeño subconjunto de datos: 

```{r}
gapminder_colombia <- filter(gapminder, country == "Colombia")
```

Ahora, creemos una serie de variables nuevas Para cada observación, queremos conocer los siguientes valores:

- PIB per cápita más alto de toda la serie (`cummax()`).
- El valor del PIB per cápita de la observación o año anterior (`lag()`).
- Esta misma variable, pero de hace 2 años (con el argumento `n =`) y del año siguiente (`lead()`).

Usamos `mutate()` para realizar la operación

```{r}
gapminder_colombia <- mutate(
  gapminder_colombia,
  gdpPercap_max = cummax(gdpPercap),
  gdpPercap_lag = lag(gdpPercap),
  gdpPercap_lag2 = lag(gdpPercap, n = 2),
  gdpPercap_lead = lead(gdpPercap)
)

# veamos el resultado, seleccionando solo variables de interes
select(gapminder_colombia, year, gdpPercap, gdpPercap_max, gdpPercap_lag, gdpPercap_lag2, gdpPercap_lead)
```

Podemos usar `lag()` y `lead()` aquí porque solo hay datos de un país y están ordenados cronológicamente por año. En paneles de datos con muchos países y años, necesitaríamos agrupar los datos por país primero, como veremos más adelante.

Un último detalle: con estas nuevas variables, podemos calcular otras cantidad de interés, como el crecimiento anual del PIB per cápita. Comparamos el PIB per cápita de un año al del año anterior:

```{r}
gapminder_colombia <- mutate(
  gapminder_colombia,
  gdpPercap_dif = gdpPercap - gdpPercap_lag,
  gdpPercap_dif_perc = gdpPercap_dif/gdpPercap_lag
)

select(gapminder_colombia, year, gdpPercap, gdpPercap_dif, gdpPercap_dif_perc)
```

Y podemos ver la crisis económica colombiana de finales del siglo XX:

```{r}
# creamos un indicador de crecimiento negativo
gapminder_colombia <- mutate(
  gapminder_colombia,
  crecimiento_signo = if_else(gdpPercap_dif_perc < 0, "neg", "pos")
)

# ahora construimos la grafica
ggplot(gapminder_colombia, aes(year, gdpPercap_dif_perc, fill = crecimiento_signo)) +
  geom_col()
```

### Cambiar clases de variables

Todos los objetos en R tienen una clase, incluyendo las columnas de una base de datos. Las principales clases de variables en R son: 

- `numeric` e `integer` corresponden a variables de tipo numérico, continuas y enteros.
- `factor`, variables categóricas definidas especialmente y con categorías y niveles, a veces con un orden explícito.
- `character`, a veces llamados *strings*, y que incluyen caracteres, texto, palabras, etc. incluyendo oraciones completas.
- `logical`, con valores `TRUE` o `FALSE` dependiendo de si se cumple una condición.
- `date`, un formato especial para fechas.
- `NA`, `NaN` e `Inf` para datos no disponibles, que no pueden ser expresados como un número o con valor infinito.

A veces, tenemos una variable tipo caracter o texto que queremos como categórica (factor). O sucede que cargamos los datos y hay una variable numérica que R interpreta como texto. Miremos cómo cambiar tipos de variables usando los datos de PolityIV que cargamos anteriormente. Seleccionemos unas pocas variables de interés:

```{r}
polity4 <- select(polity4, ccode, country, year, polity2, parreg, parcomp, exconst)
polity4
```

Hay varias funciones que nos permite hacer cambios de tipo fácilmente en conjunción con `mutate()`: `as.numeric()`, `as.factor()`, `as.integer()`, `as.character()`, etc. Vamos a convertir el código de país y el año a variables de tipo factor (variable categórica) y a (número) entero, respectivamente:

```{r}
mutate(polity4, 
       ccode = as.factor(ccode), 
       year = as.integer(year))
```

Si tenemos muchas variables que aparecen con la clase incorrecta, podemos cambiarlas masivamente usando la función `across()` dentro de `mutate()`. Esta función nos permite imponer una condición para seleccionar qué variables vamos a transformar y seleccionar una función (`as.factor()` en este ejemplo) para aplicarle a esas variables:

```{r}
mutate(
  polity4, 
  across(
    # caracteristica que tienen las variables que queremos cambiar
    is.character,
    # funcion que queremos aplicarles
    as.factor 
  )
)
```

La función `across()` es bastante útil y permite aplicar cualquier función a un conjunto de columnas con algo en común. Como ejemplo, supongamos que por alguna razón queremos modificar los valores de las variables `parreg` y `parcomp`:

```{r}
# definimos una funcion que toma una variable numerica y le suma 2
sumar2 <- function(x) {
  x+2
}

# ahora modificamos las variables
mutate(
  polity4, 
  across(
    # caracteristica que tienen las variables que queremos cambiar
    starts_with("par"),
    # funcion que queremos aplicarles
    sumar2
  )
)
```

### Variables categóricas

Ya hemos visto cómo crear nuevas variables numéricas aplicando funciones en el contexto de `mutate()`. Pero también podemos crear variables categóricas o cualitativas. En R, estas son llamadas "factores" (o *factors*). Tanto `base` como la librería `forcats` ofrecen funciones que nos ayudan a trabajar con factores.

#### Variable numérica a categórica

Primero, utilicemos los valores de una variable numérica para crear una categórica. Por ejemplo, clasifiquemos como "democracias" a los países que tienen un valor mayor que 5 en el indicador `polity2`. Para esto, la función `if_else()` nos permite evaluar con expresiones lógicas si se cumplen condiciones y reemplazar valores. A su vez, la función `factor()` le dice a R que la variable creada es categórica; es importante seguir bien los paréntesis para entender qué está pasando. Usamos `<-` para asegurarnos que los resultados queden guardados en `polity4`:

```{r}
polity4 <- mutate(
  polity4, 
  # creamos un factor llamado democracia
  democracia = factor( 
    if_else(
      # qué condición se tiene que cumplir
      condition = polity2 > 5, 
      # qué hacer si se cumple
      true = "democracia", 
      # qué hacer si no se cumple
      false = "otro" 
    ),
    # especificamos que el factor no es ordinal
    ordered = FALSE 
  )
)
```

Revisamos el resultado con `count()` que cuenta el número de observaciones en cada categoría:

```{r}
count(polity4, democracia)
```

Podemos crear mas de dos categorías a la vez usando `case_when()`, la cual es una extensión de `if_else()`. Aquí, evaluamos si cumplen con unas condiciones y creamos una variable acordemente:

```{r}
polity4 <- mutate( 
  polity4, 
  regimen = factor( # crear una nueva variable tipo factor
    case_when( 
      # condición ~ resultado
      polity2 > 5 ~ "democracia", 
      polity2 < -5 ~ "autocracia",
      # para todos los demás casos ~ resultado
      TRUE ~ "anocracia" 
    ),
    # el factor no es ordenado
    ordered = FALSE 
  )
)
count(polity4, regimen)
```

Otra forma de hacer esto es con la función `cut_number()`. A continuación, la utilizamos para dividir la variable `polity2` en 5 grupos o categorías con aproximadamente el mismo número de observaciones en cada una:

```{r}
polity4 <- mutate( 
  polity4, 
  regimen_cut = cut_number(polity2, 5)
)

# revisamos el resultado
count(polity4, regimen_cut)
```

Podemos darle nombre a las categorías que creamos con `cut_number()` y el argumento `labels = `:

```{r}
polity4 <- mutate( 
  polity4, 
  regimen_cut = cut_number(
    polity2, 5, labels = c("bajo", "med-bajo", "medio", "med-alto", "alto")
  )
)
count(polity4, regimen_cut)
```

##### Reordenar factores

Tenemos varias maneras de reordenar o recodificar factores; algunas son funciones de la librería `forcats` del `tidyverse`. Pueden consultar más sobre esta librería en (este sitio)[https://forcats.tidyverse.org/].

Si queremos especificar los niveles de un factor al crearlo, usamos el argumento `"levels ="` en `factor()`. El orden de un factor es importante, pues define la categoría base, frente a la cual comparamos e interpretamos a la hora de hacer gráficas o estimar modelos estadísticos:

```{r}
polity4 <- mutate(
  polity4, 
  regimen = factor(regimen, levels = c("democracia", "anocracia", "autocracia"))
)

count(polity4, regimen)
```

Podemos hacer algo similar -un reordenamiento manual- con `fct_relevel()` cuando tenemos una variable categórica que ya existe. Comparen el orden en el código y las diferencias en el resultado:

```{r}
polity4 <- mutate(
  polity4, 
  regimen = fct_relevel(regimen, 
                        c("autocracia", "anocracia", "democracia"))
)
count(polity4, regimen)
```

Igualmente, podemos reordenar por frecuencias, trayendo al frente a la categoría con más observaciones, la cual se convierte en nuestra categoría base o de referencia. Hacemos esto con `fct_infreq()` y es útil cuando queremos construir una gráfica:

```{r}
ggplot(polity4, aes(fct_infreq(regimen_cut))) +
  geom_bar() +
  coord_flip()
```

También podemos ordenar los niveles de un factor según los valores de otra variable con `fct_reorder()`. En la siguiente gráfica, vemos el PIB per cápita de cuatro países suramericanos para el año 2007, pero el orden de los países en la gráfica corresponde a la expectativa de vida promedio en cada país:

```{r}
gapminder_sub <- filter(
  gapminder, 
  year == max(year), 
  country %in% c("Colombia", "Argentina", "Peru", "Venezuela")
)

ggplot(gapminder_sub, aes(fct_reorder(country, lifeExp), gdpPercap)) +
  geom_col()
```

Finalmente, podemos combinar o *colapsar* categorías en una categoría de "otros" usando la función `fct_lump()`, con el argumento opcional `other_level = ` para especificar el nombre de la categoría residual (por defecto, esta queda nombrado como "Other"):

```{r}
polity4 <- mutate(
  polity4, 
  regimen_bin = fct_lump(regimen_cut, n = 2, other_level = "otros")
)

count(polity4, regimen_bin)
```

<!-- #### Variable categórica a numérica -->

<!-- Finalmente, utilizamos los valores de una variable categórica para crear una numérica discreta. Ojo: debemos asegurarnos que esto tenga sentido. Por ejemplo, en términos de democratización, ¿es igual pasar de autocracia a anocracia, que pasar anocracia a democracia? El truco que usamos es la función `recode()` que nos permite asignar nuevos valores: -->

```{r, eval=FALSE, include=FALSE}
# polity4 <- mutate(
#   polity4,
#   regimen_num = fct_recode(
#     regimen,
#     -1 = "autocracia", # valor original = valor nuevo
#     0 = "anocracia",
#     1 = "democracia"
#   )
# )
# 
# count(polity4, regimen_num)
```

## Resumir: `count()`, `group_by()` y `summarize()`

Con frecuencia, nuestros datos están agrupados: las observaciones pertenecen a grupos, indicador por una variable categórica. Por ejemplo, los países del mundo están ubicados en distintos continentes. Como hemos visto con anterioridad, la función `count()` nos muestra el número de observaciones en cada grupo, definido por una variable categórica (factor o caracter):

```{r}
count(gapminder, continent)
```

### Tablas cruzadas

La función `count()` sirve además para hacer tablas cruzadas con dos variables categóricas. Veamos cómo funciona. Primero, creamos una nueva variable para niveles altos de PIB per cápita (aquellos países-año por encima de la media global):

```{r}
gapminder <- mutate(
  gapminder, 
  pib_dummy = if_else(
    gdpPercap > mean(gdpPercap, na.rm = TRUE), "alto", "bajo"
  )
)
```

Ahora, tabulamos o "cruzamos" las variables con `count()`:

```{r}
count(gapminder, continent, pib_dummy)
```

Las tablas cruzadas nos permiten ver rápidamente posibles relaciones entre variables categóricas. Por tanto, son parte central de la caja de herramientas de las ciencias sociales. 

Digamos que queremos exportar la anterior tabla cruzada porque queremos incluirla en un documento externo (y por alguna razón no estamos usando RMarkdown). En este caso, una posibilidad es usar la libreria `knitr` y la función `kable()`. Primero, creamos la tabla como un objeto:

```{r}
library(knitr)
tabla_cruzada <- kable(
  count(gapminder, continent, pib_dummy), # datos
  format = "html", # formato .html
  col.names = c("Continente", "Nivel PIB", "Casos"), # nombres de columnas
  caption = "Tabla cruzada" # titulo
)
```

Y luego guardamos la tabla con `write_file()` de `readr`, especificando el directorio y el nombre del archivo al cual queremos mandar la tabla:

```{r}
write_file(tabla_cruzada, "output/tabla_cruzada.doc")
```

Luego, podemos abrir el archivo y copiar la tabla.

### Agrupar y resumir

Aprovechamos que los datos frecuentemente pueden ser agrupados para aplicar operaciones que los resumen, dándonos información para cada grupo, definido por una variable categórica. Esto nos permitirá ver diferencias y comparar entre democracias y autocracias o entre observaciones en un grupo de tratamiento y un grupo de control experimental.

Las dos funciones que vamos a utilizar para esto son `group_by()` y `summarize()`. Por si sola, `summarize()` resume variables y el resultado siempre es un solo valor, al cual le damos un nuevo nombre. Por ejemplo, la media de la variable `lifeExp` en `gapminder`:

```{r}
summarize(gapminder, lifeExp_media = mean(lifeExp, na.rm = TRUE))
```

Esta es una alternativa a:

```{r}
mean(gapminder$lifeExp, na.rm = TRUE)
```


Por el otro lado, `group_by()` por si solo aparentemente no hace mucho -- noten que el `tibble` resultante nos indica que este objeto está agrupado y que hay `r nrow(distinct(gapminder, country))` grupos:

```{r}
group_by(gapminder, country)
```

En este punto, `group_by()` nos permite hallar valores razagados y adelantadas por grupo, como hicimos anteriormente, pero con una base de datos en donde hay más de un grupo (más de un país en este caso específico):

```{r}
select(mutate(
  group_by(gapminder, country),
    gdp_lag = lag(gdpPercap), 
    gdp_lead = lead(gdpPercap)
), country, year, gdp_lag, gdp_lead)
```

Pero, por sus poderes combinados... `group_by()` junto a `summarize()` crea uno de los "combos" mas potentes de `dplyr` y el `tidyverse`. Agrupamos los datos según una variable (usualmente categórica) y los resumimos, obteniendo una observación por grupo. Así, calculamos la media de la expectativa de vida de cada año:

```{r}
summarize(
  # agrupamos los datos
  group_by(gapminder, year),
  # creamos una columna nueva que resume una variable para cada grupo
  lifeExp_media = mean(lifeExp, na.rm = TRUE) 
)
```

A veces queremos agregar el número de observaciones hay en cada grupo, como cuando usamos `count()`. Simplemente agregamos otra columna y usamos `n()`:

```{r}
summarize(
  group_by(gapminder, continent), 
  num_obs = n()
)
```

Digamos que queremos saber cuál ha sido el nivel de PIB per cápita más alto para cada país en la muestra:

```{r}
summarize(
  group_by(gapminder, country), 
  gdpPercap_max = max(gdpPercap, na.rm = TRUE)
)
```

El combo `group_by()` + `summarize()` es clave porque permite empezar a explorar relaciones entre variables categóricas y numéricas, algo central en las ciencias sociales. Por ejemplo, continente y PIB per cápita:

```{r}
summarize(
  group_by(gapminder, continent), 
  gdpPercap_media = mean(gdpPercap, na.rm = TRUE),
  gdpPercap_desv = sd(gdpPercap, na.rm = TRUE)
)
```

Y no tiene por qué terminar ahí: combinando `summarize()`, `group_by()` y `across()` podemos aplicar una lista de múltiples funciones a un conjunto de variables con una característica en común:

```{r}
summarize(
  group_by(gapminder, continent), 
  # resumir variables de clase double, un tipo de variable numérica no entera
  across(where(is.double), 
         list(media = ~mean(.x, na.rm = TRUE), 
              desv = ~sd(.x, na.rm = TRUE), 
              mediana = ~median(.x, na.rm = TRUE)))
)
```

Finalmente, si vamos a realizar más operaciones con los datos después de agruparlos y resumirlos, pero *no* queremos que sigan agrupados, usamos la función `ungroup()`. De lo contrario todas las operaciones siguientes se harían también por grupos:

```{r}
ungroup(
  summarize(
  group_by(gapminder, continent),
  media_pib = mean(gdpPercap, na.rm = TRUE)
  )
)
```

## Datos no disponibles: `na_if()`, `replace_na()` y `drop_na()`

A veces, no tenemos información para una característica de un caso. En otras palabras, hay un dato no disponible (*not available*). En vez de una celda en blanco, marcamos el dato específicamente como no disponible. En R, los datos no disponibles **deben** aparecer como `NA` para poder tratarlos correctamente. El valor `NA` es distinto al texto "NA" o cosas como "N/A", "No disponible" y "-".

Es supremamente importante tener en mente los valores `NA` y los datos no disponibles por varias razones. Resaltemos dos. Primero, es imposible calcular una media de un vector numérico (una columna con un índice de democracia, por ejemplo) si hay un valor marcado como `NA` o "N/A" y similares. De la misma manera, calcular una media de un vector numérico con valores como "-999" nos dará un resultado, pero errado. Segundo, algunas de las operaciones estadísticas que veremos más adelante -específicamente los modelos de regresión- asumen que no hay datos no disponibles y, por tanto, remueven automáticamente del análisis cualquier observación con valores `NA` en alguna de las variables de interés. Si los valores no disponibles dependen de alguna característica importante (por ejemplo, no tenemos datos sobre capacidad estatal en los países pobres) nuestro análisis podría terminar siendo sobre una muestra problemática en términos de sesgo de selección.

Las librerías `dplyr` y `tidyr` incluyen tres funciones para lidiar con valores `NA`: `na_if()`, `replace_na()` y `drop_na()`. Otras librerías como `naniar` ofrecen funciones adicionales. También existen técnicas avanzadas para imputar valores no disponibles, pero no las cubriremos aquí.

### Convertir a NA

Algunas bases de datos especifican en el libro de códigos como vienen los datos no disponibles. En el caso de Polity IV, los valores `-66`, `-77` y `-88` pueden ser interpretados como valores no disponibles. Sin embargo, no vienen marcados como valores `NA`, así que R no los interpreta adecuadamente. Si miramos los valores de la variable `exconst` podemos entender un poco mejor a qué nos referimos:

```{r}
count(polity4, exconst)
```

Si intentamos hallar la media de esta variable, sin antes corregir estos tres valores, el resultado va a ser distinto, porque R los incluye en el cálculo, ya que no entiende que son `NA`. Más adelante veremos la diferencia.

Ahora, cambiemos estos valores a `NA` usando la función `na_if()` dentro de `mutate()`:

```{r}
polity4 <- mutate(
  polity4,
  # variable nueva; podríamos reescribir la original
  exconst_mod = na_if(exconst, "-66") 
  
) 

# revisamos que los convertimos a NA
count(polity4, exconst_mod) 
```

Comparemos los resultados, calculando la media de la variable original y la corregida:

```{r}
summarize(
  polity4, 
  media_exconst = mean(exconst, na.rm = TRUE),
  media_exconst_mod = mean(exconst_mod, na.rm = TRUE)
)
```

Este cambio a `NA` lo podemos realizar para una variable solamente, para varias (con `across()`) o para toda la base de datos. A continuación, vemos cómo realizar el cambio para *todas* las columnas de una base de datos -- deben estar seguros de que esto tiene sentido:

```{r}
polity4 <- na_if(polity4, "-66") 
```

Como `-77` y `-88` también pueden ser vistos como `NA`, repetimos la operaciones:

```{r}
polity4 <- na_if(polity4, "-77") 
polity4 <- na_if(polity4, "-88") 
count(polity4, exconst)
```

En realidad, esta operación es un "*hack*" y los desarrolladores de `tidyverse` recomiendan usar `across()` así:

```{r}
mutate(
  polity4,
  across(everything(), ~na_if(.x, "-77"))
)
```

### Reemplazar NA con otro valor

Puede suceder que hay valores que aparecen como `NA` pero que sabemos que no lo son. Por ejemplo, puede que sean igual a un valor de 0 y no indiquen realmente una falta de datos o información. Para tratar con estas situaciones, usamos `replace_na()`. Aquí creamos una variable nueva donde los valores `NA` de la columna `exconst_mod` pasan a ser 0:

```{r}
polity4 <- mutate(
  polity4, 
  exconst_mod2 = replace_na(exconst_mod, 0)
) 

count(polity4, exconst_mod2)
```

### Descartar NA

Por último, si queremos descartar las observaciones que tienen valores `NA` en una o varias variables, usamos la función `drop_na()`. Nuevamente, es aplicable para una variable -descartar observaciones con `NA` en esa columna en particular- o para toda la base de datos -descartar observaciones con `NA` en cualquier variable o columna. Comparemos el número de observaciones de nuestra base de datos cuando descartamos filas con `NA` en la variable `country`:

```{r}
nrow(drop_na(polity4, country))
```

Con el número de filas restantes cuando descartamos filas con `NA` en cualquier columna:

```{r}
nrow(drop_na(polity4))
```

## Simplificar código: tuberías `%>%`

Ya que revisamos las principales formas de trabajar con datos, quizás nos parezca que nuestro código a veces se vuelve engorroso y largo. En particular, se vuelve difícil hacerle seguimiento a todos los paréntesis incluidos cuando aplicamos varias funciones como `group_by()`, `summarize()` y `mutate()`. En esta sección, damos un paso gigantesco hacia la simplificación de nuestro código a través del uso del operador `%>%`. 

El operador `%>%` (*pipe*, tubo o tubería) sirve para simplificar nuestro código. Viene de la librería `magrittr` y de pronto el logo de esta librería nos ayuda a entender la referencia en el nombre:

![Logo de la librería magrittr.](images/magrittr-logo.png)

El *pipe* es usado extensamente en el `tidyverse` -- si cargamos esta librería, automáticamente podemos usar `%>%` sin necesidad de cargar `magrittr`. Para entender la utilidad de los *pipes*, comparemos tres formas de usar varias funciones al mismo tiempo:

1. Anidadas: se vuelve confuso tener tantos paréntesis.

```{r}
head(arrange(select(filter(gapminder, year == 2007, continent == "Americas"), country, gdpPercap), desc(gdpPercap)))
```

Romper el código en líneas -como hemos hecho hasta ahora- ayuda un poco a entender qué está pasando, pero sigue exigiendo jugar una ronda de "veo, veo":

```{r}
head(
  arrange(
    select(
      filter(gapminder, year == 2007, continent == "Americas"), where(
        is.numeric
      )
    ), 
    desc(gdpPercap)
  )
)
```

2. Paso a paso: es ineficiente, pues estamos crenado nuevos objetos "intermedios" o temporales que luego debemos eliminar (para eso está `rm()`) o, de lo contrario, ocupan memoria en nuestro equipo.

```{r}
gapminder_2007 <- filter(gapminder, year == 2007, continent == "Americas")
gapminder_2007 <- select(gapminder_2007, where(is.numeric))
gapminder_2007 <- arrange(gapminder_2007, desc(gdpPercap))
head(gapminder_2007)
rm(gapminder_2007)
```

3. *Pipes*: se puede leer como "... y entonces...". Tomamos un objeto, le aplicamos una función y entonces se lo pasamos a otra función y hacemos algo más. Se leen izquierda-derecha y de arriba-abajo, si partimos el código en líneas. El objeto que pasamos por el *pipe* entra como primer argumento de la siguiente función.

Empecemos con un ejemplo sencillo:

```{r}
# tomar un vector numérico
c(1, 1, 2, 3, 5, 8, 13, 21) %>% 
  # encontrar la media
  mean() %>% 
  # redondear el resultado
  round() 
```

Pueden usarse como "tuberías" que conectan varias funciones, como `filter()`, `select()` y `arrange()`, cada una construyendo sobre los resultados que arroja la anterior, para analizar una base de datos paso a paso en un solo bloque de código legible:

```{r}
# tomar una base de datos
gapminder %>% 
  # filtrar por valores de year y continent
  filter(year == 2007, continent == "Americas") %>% 
  # seleccionar solo las variables numericas
  select(where(is.numeric)) %>%
  # ordenar descendente segun gdpPercap
  arrange(desc(gdpPercap)) %>% 
  # ver las primeras filas del resultado
  head() 
```

Las funciones del `tidyverse` están diseñadas para trabajar con el operador `%>%`; por eso, el primer argumenta de estas funciones siempre es una base de datos. Si usamos una función con una sintáxis distinta, podemos usar `.` para seguir usando los pipes. Por ejemplo, en un modelo de regresión lineal usando la función básica `lm()`, el argumento `data = ` no es el primero, en pero la función `summary()` (para ver los resultados del modelo) sí. Luego:

```{r}
gapminder %>%
  lm(lifeExp ~ gdpPercap, data = .) %>%
  summary()
```


Con tuberías más largas, podemos responder a preguntas interesantes y comparaciones relevantes de forma más eficiente, siempre teniendo claro cuáles fueron los pasos que seguimos. 

Por ejemplo, digamos que queremos encontrar la media continental del PIB per cápita en el último año para el que tenemos información, porque estamos interesados en explorar la variación espacial en la riqueza de las naciones. ¿Cómo lo hacemos? ¡Pues armamos una tubería con `group_by()` y `summarize()`! Ya sabemos que comparar medias entre dos grupos nos permite ver la relación entre una variable numérica y una categórica:

```{r}
gapminder %>%
  # el ultimo año presente en los datos
  filter(year == max(year, na.rm = TRUE)) %>% 
  # agrupar por continente
  group_by(continent) %>% 
  # hacemos un resumen
  summarize(
    pib_media = mean(gdpPercap, na.rm = TRUE),
    pib_mediana = median(gdpPercap, na.rm = TRUE),
    pib_max = max(gdpPercap, na.rm = TRUE),
    pib_min = min(gdpPercap, na.rm = TRUE),
    pib_de = sd(gdpPercap, na.rm = TRUE),
    num_casos = n()
  )
```

O quizás nos interesa saber cuál es el promedio de varios indicadores de la base de datos de Polity IV para cada tipo de régimen (usando la variable categórica que creamos anteriormente en este capítulo):

```{r}
polity4 %>%
  # solo unos años
  filter(year %in% c(1997:2017)) %>%
  # agrupamos por tipo de régimen (demo-anocracia-auto)
  group_by(regimen) %>% 
  # hacemos un resumen
  summarize( 
    media_polity2 = mean(polity2, na.rm = TRUE),
    media_parreg = mean(parreg, na.rm = TRUE),
    media_parcomp = mean(parcomp, na.rm = TRUE)
  )
```

Con `across()` seleccionamos variables a resumir si cumplen alguna condición. En este ejemplo además incluimos `ungroup()` al final porque creemos que podríamos hacer más operaciones, pero no necesariamente a nivel de grupos:

```{r}
polity4 %>%
  filter(year %in% c(1997:2017)) %>% # solo unos años
  group_by(regimen) %>% # agrupamos por tipo de régimen (demo-ano-auto)
  # hacemos un resumen para ciertas variables
  summarize( 
    across(
      where(is.numeric), ~mean(.x, na.rm = TRUE)
    )
  ) %>%
  ungroup()
```
Vale la pena acostumbrarse a cerrar un *pipe* como este con `ungroup()` si queremos seguir la tubería sin hacer operaciones por grupo; de lo contrario todas las operaciones adicionales se harían por grupos.

### Tablas cruzadas con `%>%`

Las tablas cruzados que hicimos arriba también se benfician del uso de *pipes*. Hagamos una tabla que cuente y muestre la relación entre la variable continente (`continent`) y la variable binaria de nivel de ingreso alto o bajo que construimos anteriormente (`pib_dummy`). Ahora, además de la frecuencia de observaciones por grupo, queremos las proporciones por grupo. Combinamos varias funciones usando *pipes*:

```{r}
tabla2 <- gapminder %>%
  count(continent, pib_dummy) %>%
  group_by(continent) %>%
  mutate(prop = round(n/sum(n), 2))

tabla2
```

Al final, exportamos el resultado a un archivo de Word:

```{r}
tabla2 %>%
  kable(
    format = "html",
    col.names = c("Continente", "Nivel PIB", "Casos", "Prop."),
    caption = "Tabla cruzada",
    format.args = list(decimal.mark = ",")
  ) %>%
  write_file("output/tabla2.doc")
```

### Agregación: cambiar niveles de análisis

Otro uso común de `group_by()` seguido de `summarize()` es para agregar datos. Al agrupar y resumir podemos cambiar el nivel de análisis. Por ejemplo, en vez de país-año podemos pasar la base de datos `gapminder` al nivel continente-año: cada fila sería un continente en un año y las columnas son resúmenes (la media en este caso) de toda slas observaciones en cada continente. Por cierto, porque el inglés británico existe, tanto `summarize()` como `summarise()` son válidas:

```{r}
gapminder_cont <- gapminder %>%
  group_by(continent, year) %>%
  summarise(across(lifeExp:gdp, ~mean(.x, na.rm = TRUE))) %>%
  ungroup()

gapminder_cont %>%
  sample_n(10)
```

Por último, estos *pipes* y los verbos que hemos utilizado sirven para hacer gráficas de manera eficiente y clara, lo cual veremos con más detalle en capítulos siguientes:

```{r}
gapminder_cont %>% # tomar datos
  ggplot(mapping = aes(x = log(gdpPercap), y = lifeExp)) + # seleccionar variables
  geom_point(color = "darkblue") + # gráfica de dispersion
  labs(x = "PIB per cápita (USD, log.)", y = "Expectativa de vida al nacer (años)") # titulos de los ejes
```

Construyamos una gráfica similar, pero trabajando con los datos a nivel-país año:

```{r}
gapminder %>% # tomar datos
  filter(year %in% c(1962, 1972, 1982, 1992, 2002)) %>% # filtrar para incluir ciertos anos
  ggplot(mapping = aes(x = log(gdpPercap), y = lifeExp)) + # seleccionar variables
  geom_point(color = "darkblue", alpha = 0.5) + # gráfica de dispersion, transparencia 50%
  labs(x = "PIB per cápita (USD, log.)", y = "Expectativa de vida al nacer (años)") # titulos de los ejes
```

Finalmente, si queremos ver las trayectorias de los distintos continentes, usamos el agumento `color =` de `ggplot()` para graficar una línea de color distinto para cada grupo:

```{r}
gapminder_cont %>%
  ggplot(aes(year, log(gdpPercap), color = continent)) +
  geom_line() +
  labs(x = "Año", y = "PIB per cápita (USD, log.)", color = "Continente")
```

## Ordenar y reformatear: `pivot_()`

Muy frecuentemente, los datos que encontramos están *desordenados*. Por ejemplo, usualmente debemos corregir los `NA`, cambiar el tipo de una variable, recodificar un factor para cambiar la categoría base o quizás calcular un pedazo de información faltante.

Otro paso habitual es "limpiar" los nombres de las variables. No es recomendable tener espacios o caracteres especiales en los nombres de las variables y en general de los objetos en R. La librería `janitor` facilita hacer estos cambios con la función `clean_names()`, la cual automáticamente cambia el formato del nombre de las variables a `snake_case` en donde todos los caracteres están en minúsculas y los espacios son reemplazados por guiones bajos. Veamos qué hace esta función con `gapminder`:

```{r}
gapminder %>% 
  clean_names()
```

Lidiar con `NA` y nombres de variables es sencillo. Más complejo es asegurarse que una base de datos estén ordenadas ("*tidy data*"): cada fila debe ser una observacion y cada columna una variable. Es el principio rector del `tidyverse()`. A veces, decimos que una base de datos en formato *tidy* está en formato "largo", en oposición a "ancho". Por ejemplo, `gapminder` está en formato largo y *tidy*. Cada fila es una observación, cada columna una variable:

```{r}
sample_n(gapminder, 10)
```

A continuación, vamos a crear un ejemplo sencillo de datos desordenados en formato ancho:

```{r}
ancho <- tibble(
  pais = c("Colombia", "Argentina", "Brazil"),
  indicador_2000 = rnorm(3, 2),
  indicador_2010 = rnorm(3, 3),
  indicador_2020 = rnorm(3, 4)
)
ancho
```

Comparemos con los mismos datos en formato largo. Según el principio *tidy*, debería haber tres columnas: `pais`, `indicador` y `ano`. Aquí, en vez de hacerlo completamente "a mano", usamos `expand_grid()` para repetir los nombres de país y años, para luego agregar el indicador.

```{r}
largo <- expand_grid(
  pais = c("Colombia", "Argentina", "Brazil"),
  ano = c(2000, 2010, 2020)
) %>%
  mutate(indicador = rnorm(9, 3))
largo
```

Pero, ¿cómo hacemos para pasar fácilmente de un formato al otro? Para reformatear datos de esta manera hacemos uso de funciones de la librería `tidyr`. Usamos `pivot_wider()` para pasar de largo a ancho y `pivot_longer()` para hacer lo contrario.

### Largo a ancho

Ocasionalmente, tenemos datos en formato largo y queremos pasarlos a un forma más ancha. Esto puede ser porque queremos hacer una tabla para presentar la información (una tabla muy larga es difícil de leer) o porque queremos cambiar el nivel de análisis de los datos ("agregarlos") para analizarlos o graficarlos. Usamos `pivot_wider()`:

```{r}
gapminder_ancho <- gapminder %>%
  pivot_wider(
    # especificar columnas que identifican cada observacion
    id_cols = country,
    # de donde salen los nombres de las nuevas columnas
    names_from = year,
    # opcional: un prefijo para las nuevas variables
    names_prefix = "year_",
    # de donde salen los valores de las nuevas celdas
    values_from = lifeExp, 
  )

gapminder_ancho
```

### Ancho a largo:

Es más común tener que pasar de ancho (desordenado) a largo (ordenado). Usamos `pivot_longer()` para realizar este reformateo:

```{r}
gapminder_largo <- gapminder_ancho %>% 
  pivot_longer(
    # cuales variables vamos a transformar
    cols = -country,
    # nombre de la nueva columna de las viejas columnas
    names_to = "year",
    # opcional: si las variables a transformar tienen un prefijo
    names_prefix = "year_",
    # nombre de la nueva columna que contiene los valores de las celdas
    values_to = "lifeExp"
  ) %>%
  arrange(country, year)

gapminder_largo
```

Como ejemplo final, convertimos el ejemplo que construimos arriba:

```{r}
ancho %>%
  pivot_longer(
    -pais,
    names_to = "ano",
    names_prefix = "indicador_",
    values_to = "indicador"
  )
```

### Ejercicio: datos del Banco Mundial

La librería `tidyr` incluye unos datos del Banco Mundial que vamos a utilizar para dar un ejemplo más avanzado:

```{r}
world_bank_pop
```

Los datos está en formato ancho. Nuestro objetivo es tener una base de datos donde cada variable esté en una columna y cada fila sea una observación. Nuestro problema es que el año está en multiples columnas, en vez de tener su propia columna. Entonces, usamos `pivot_longer()`:

```{r}
pop2 <- world_bank_pop %>%
  pivot_longer(
    # comillas para que R entienda que son nombres de columnas, no valores
    `2000`:`2017`, 
    names_to = "year", 
    values_to = "value"
  )
pop2
```

Aún así, tenemos que considerar la variable `indicator`:

```{r}
pop2 %>% 
  count(indicator)
```

Aquí:

- `SP.POP.GROW` es la tasa de crecimiento poblacional.
- `SP.POP.TOTL` es la población total.
- `SP.URB.*` es lo mismo, pero para áreas urbanas

Dividamos `indicator` en dos variables, área (total o urbana) y
la variable en sí (población o crecimiento). Para esto, usamos la función `separate()`:

```{r}
pop3 <- pop2 %>% 
  separate(indicator, c(NA, "area", "variable"))
pop3
```

Ahora podemos terminar de limpiar los datos al convertir los valores `TOTAL` y `GROW` en variables/columnas propias:

```{r}
wb_tidy <- pop3 %>% 
  pivot_wider(names_from = variable, values_from = value)
wb_tidy
```

O, en un solo bloque de código con *pipes*:

```{r}
world_bank_pop %>%
  pivot_longer(
    # comillas para que R entienda que son nombres de columnas, no valores
    `2000`:`2017`, 
    names_to = "year", 
    values_to = "value"
  ) %>% 
  separate(indicator, c(NA, "area", "variable")) %>% 
  pivot_wider(
    names_from = variable, 
    values_from = value
  )
```

Por último, para usar los datos más adelante sin tener que repetir este proceso, guardamos los datos como archivo con extensión `.csv`:

```{r}
write_csv(wb_tidy, "data/wb_tidy.csv")
```

## Combinar/unir: `_join()`

Otro problema de datos común: tenemos dos bases de datos relacionadas, de pronto porque ambas incluyen información sobre los mismos casos, y queremos combinarlas. Volvamos a los datos de Polity IV:

```{r}
polity4
```

Pero esta base de datos solo tiene informacion sobre algunas características institucionales de la democracia. ¿Qué pasa si queremos explorar la relación de estas medidas con otros factores? Necesitaríamos unirla con otra base de datos que tenga información sobre los mismos casos (o un subconjunto de estos). Por ejemplo, miremos la base de datos _Database of Political Institutions_. Cargamos el archivo (con extensión `.dta` de Stata, que abrimos cortesía de la librería `haven`), seleccionamos unas variables y hacemos un poco de limpieza de estos usando los trucos que aprendimos:

```{r, warning = FALSE, message = FALSE, cache = TRUE}
dpi <- read_dta("data/DPI2017.dta") %>%
  select(countryname, ifs, year, system, pr, numopp) %>%
  zap_labels() %>% # quita las etiquetas de variable de Stata
  na_if("-999")

sample_n(dpi, 10)
```

Ahora tenemos dos bases de datos y queremos unirlas o combinarlas. Seguimos tres pasos para alcanzar este objetivo.

1. Encontrar variables en común.
2. Combinar las dos bases de datos.
3. Guardar el resultado como un nuevo objeto en R.

### Variables en común

Debe haber variables en común para poder unir dos bases de datos. También debemos pensar en la unidad de análisis: ¿a qué corresponde cada fila en las bases de datos? 

En este ejemplo, ambas bases de datos están en un formato largo de país-año: cada fila es un país observado en un año (repetidamente, o sea, es un panel). Entonces, podemos usar el año y el nombre de los de países para unir las bases de datos pues son elementos en común. Por un lado, `polity4` y `dpi` ambas tienen la columna `year` que representa el año de la observación. 

Por otro lado, es recomendable usar códigos de país, en vez de nombres, ya que los códigos tienen estándares y los nombres no tanto (y dependen del idioma también). Los códigos de país de `dpi`, que están en la columna `ifs`, siguen el estándar del Fondo Monetario Internacional (FMI). Por tanto, convertimos los codigos de `polity4` a ese formato, apoyándonos en la libreria `countrycode`. Creamos una nueva variable que aloja los códigos de país según el estándar del FMI, usando los códigos de país que ya había en `polity4` (la columna `ccode`, que sigue el estándar numérico del Correlates of War, COW) como fuente.

```{r}
polity4 <- polity4 %>%
  mutate(
    ifs = as.character(countrycode( 
      # variable de origen
      sourcevar = ccode, 
      # formato de origen: COW numerico
      origin = "cown",
      # formato de destino: estandar ISO 3 caracteres
      destination = "iso3c" 
    ))
  ) %>%
  select(ifs, ccode, year, polity2, regimen)
polity4
```

### Combinar bases de datos

Ya tenemos la primera parte del proceso: encontramos variables en común. Para unir o combinar las bases de datos, usamos la familia de funciones `*_join()` de `dplyr`. 

Existen varios tipos de "joins". Podemos ejecutar `?dplyr::join` para ver todas las opciones. Hay dos grandes categorías, cada una con varios tipos de "joins" o combinaciones. Asumiendo que `x` y `y` son dos bases de datos relacionadas con variables en común, tenemos:

- Joins para "mutar" datos: todas toman dos bases de datos (X y Y) y las combinan Combinar variables de X y de Y
    - `left_join(x, y)`: El mas comun es left_join(X, Y) Mantiene todas las filas de X y todas las columnas de X y Y Filas de X sin pareja en Y tienen NA en las nuevas columnas
    - `inner_join(x, y)`: Mantiene solo las filas de X que tienen pareja en Y y todas las columnas de X y Y
Si hay multiples parejas, mantiene todas las combinaciones
    - `right_join(x, y)`: Complemento de left_join()
Mantiene todas las filas de Y y todas las columnas de X y Y
Filas de Y sin pareja en X tienen NA en las nuevas columnas
    - `full_join(x, y)`: Combinacion completa Mantiene todas las filas y columnas de X y Y. Si no hay parejas, da NA en esas columnas
    
- Joins para "filtrar" datos: unir para mantener las filas de X
    - `semi_join(x, y)`: Todas las filas de X con pareja en Y
Solo columnas de X
    - `anti_join(x, y)`: Todas las filas de X sin pareja en Y Solo columnas de X

Usualmente, utilizamos `left_join()`, la cual es la más común y cubre la mayoría de nuestras necesidades. Esta función une las dos bases de datos, agregando las columnas de una (aquí, `dpi`) a la otra (`polity4`). Este "join" mantiene todas las filas de la primera base de datos (`polity4`), las filas de ambas que coinciden (según las variables en común que especificamos) y todas las columnas de las dos bases de datos. Las filas de la primera base de datos que no tienen una "pareja" en la otra, aparecen con valores `NA` en las nuevas columnas (las de `dpi` que se agregan a `polity4`). Revisamos mirando algunos países:

```{r}
datos <- polity4 %>%
  left_join(
  dpi,
  # variables para combinar; deben tener el mismo nombre y tipo
  by = c("ifs", "year") 
)

datos %>% 
  select(ifs, year, polity2, regimen, pr, numopp) %>% 
  sample_n(10)
```

Podemos guardar o exportar este nuevo objeto en diversos formatos. Por ejemplo, `write_excel_csv()` crea archivos `.csv` para Excel:

```{r}
write_excel_csv(datos, file = "data/datos_polity_dpi.csv")
```

Unir estas dos bases nos permite evaluar más hipótesis. Podríamos sugerir que la presencia de una oposición fuerte (en términos de su presencia en el legislativo) lleva a un nivel de democracia más alto en términos de límites al ejecutivo. O al revés: cuando hay niveles de democracia liberal altos en los que se limita el poder del ejecutivo, es más probable que la oposición creza. Pero, ¿sí hay alguna asociación empírica entre el número de curules que tiene la oposición y el nivel de democracia de un país?

```{r, warning = FALSE}
datos %>%
  ggplot(aes(x = factor(polity2), y = numopp)) +
  geom_boxplot() +
  labs(x = "Indicador de democracia", y = "Número de curules de la oposición")
```

¿Qué conclusiones podemos sacar?

### Homicidios en Medellin

Un último ejemplo para entender cómo unir bases de datos y lo que esto nos permite hacer. Supongamos que estamos interesados en analizar los homicidios de Medellín por zona a través del tiempo. Sin embargo, solo tenemos datos sobre homicidios en Medellin (tomados del SISC) en formato comuna-año. ¡No podemos hacer el análisis por zona si no tenemos una columna que nos indique la zona a la que pertenece cada observación!

```{r}
homicidio <- read_csv("data/mde_homicidio.csv")
homicidio
```

Afortunadamente, encontramos un archivo `.csv` que contiene el listado comunas y corregimientos de Medellín y las zonas a las que pertenecen. Está en formato comuna-año para preparar un panel de datos y podemos usarlo para añadir a los datos sobre homicidios las variables `cod_zona` y `nom_zona`. Esto nos ahorra tener que clasificar las observaciones a mano.

```{r}
mde <- read_csv("data/mde_df.csv")
mde
```

En ambas bases de datos hay codigos de comuna y años en común. Y las variables tienen la misma clase (caracter y numérico, respectivamente). Están relacionadas y podemos unirlas; queremos unirlas porque nos interesan los homicidios por zona, no por comuna. Como ya habíamos mencionado, podemos especificar las columnas que queremos usar para combinar las bases de datos (las columnas que identifican a cada observación). Si tienen nombres distintos en las dos bases de datos, podemos ser más explícitos usando `"nombre_en_x" = "nombre_en_y"`. 

```{r}
mde_right <- left_join(
  homicidio, mde, 
  by = c("cod_comuna" = "cod_comuna", "ano" = "ano")
)
mde_right
```

Ahora tenemos la información necesaria para nuestro análisis. Empezamos usando `group_by()` y `summarize()` para agregar los datos a nivel de zona-año: ahora, tenemos el número de homicidios por zona en cada año:

```{r}
mde_zonas <- mde_right %>%
  # agrupar por zona y ano
  group_by(nom_zona, ano) %>% 
  summarize(
    # homicidios por comuna y ano 
    homicidios_total = sum(homicidios_total, na.rm = TRUE) 
  ) %>% 
  ungroup() %>%
  # eliminar NA
  drop_na() 

mde_zonas
```

Por último, construimos una gráfica con funciones de `ggplot2`, capa por capa: una serie de tiempo anual de los homicidios en la ciudad, zona a zona (`color = nom_zona` crea una línea por zona de la ciudad). Agregamos títulos, cambiamos colores, etc. y guardamos la gráfica como un archivo con extensión `.png` usando `ggsave()`:

```{r}
mde_zonas %>%
  # asignar variables
  ggplot(aes(x = ano, y = homicidios_total, color = nom_zona)) + 
  # gráfica de lineas
  geom_line(size = 1, alpha = 0.75) + 
  # etiquetas de eje X
  scale_x_continuous(breaks = seq(min(mde_right$ano), max(mde_right$ano))) + 
  labs(
    # título
    title = "Heterogeneidad temporal y espacial del homicidio en Medellín", 
    # subtítulo
    subtitle = "Homicidios por zona, 2003-2018", 
    # pie de imagen
    caption = "Fuente: Elaboración propia con datos del \nSistema de Información para la Seguridad y Convivencia (SISC).", 
    # títulos de ejes y leyenda
    x = NULL, y = "Número de homicidios", color = NULL 
  ) + 
  # mover leyenda
  theme(legend.position = "bottom") 
```

## Repaso

Trabajar con bases de datos:

<!-- - Subir datos a la nube usando la opción `Upload` de las pestaña `Files`. -->
- Cargar datos: usamos las funciones incluidas en `readr`, `readxl` o `haven`.
- Limpiar: `na_if()` para convertir a `NA`.
- Seleccionar y realizar subconjuntos de datos:
    - Columnas/variables/propiedades con `select()`.
    - Filas/observaciones/casos con `filter()`.
- Crear/modificar variables: 
    - `%>%` ("pipes") para pasar objetos a las funciones y concatenar varias funciones seguidas.
    - `mutate()` para crear nuevas variables usando variables existentes, por ejemplo, para crear proporciones y porcentajes.
    - `across())` para crear/cambiar múltiples variables al mismo tiempo.
    - `as.numeric()`, `as.factor()`, `as.integer()`, `as.character()` para cambiar la clase de una variable.
    - `if_else()` crea una variable dummy/binaria.
    - `case_when()` crea una variable nominal u ordinal con más de 2 categorías.
    - `factor()`  y funciones `fct_*()` para crear un factor o cambiar su orden y categorías.
- Resumir y agregar datos con `group_by()` y `summarize()`. ¡No olviden desagrupar con `ungroup()`!
- Modificar la estructura de bases de datos:
    - Cambiar de formato largo a ancho con `pivot_longer()` y `pivot_wider()`.
    - Combinar dos bases de datos relacionadas con `left_join()` y similares. 

## Taller: manejo de datos

### Crear una base de datos

Construir, guardar e imprimir a la consola un objeto `tibble` en R llamado `datos_pib` que contenga la siguiente información en filas y columnas:

- Colombia es un país democrático en América con un PIB per cápita de 6,651 USD y una expectativa de vida de 77 años.
- En el régimen dictatorial de Corea del Norte, ubicado en Asia, la expectativa de vida es de unos 67 años.
- En España, una democracia europea, la expectativa de vida es 83 años y el PIB per cápita es de 30,524 dólares.
- El PIB per cápita de Arabia Saudí, una dictadura en Asia donde la expectativa de vida es 73 años, es de 23,219 USD.
- En Sudán, el PIB per cápita es de 977 dólares y la expectativa de vida es 61 años; este país es una dictadura africana.

Usando `datos_pib`, encontrar (1.0 punto):

- El promedio del PIB per cápita para toda la muestra.
- La correlación de esta variable con la expectativa de vida al nacer.

### Mostrar relaciones 

Usando la función apropiada, cargar el archivo de datos `datos_taller1.csv` como un objeto tipo `tibble`. El archivo está disponible  [aquí](https://github.com/josefortou/lab-book/blob/master/data/) y recuerden moverlo a la carpeta `"data/`.

La base de datos incluye las siguientes variables tomadas de [Varieties of Democracy, v. 10](https://www.v-dem.net/en/data/data-version-10/):

- `vdem_country_name`: nombre del país.
- `year`: año de la observación.
- `v2x_polyarchy`: indicador (numérico) de democracia electoral.
- `v2elparlel`: tipo de sistema electoral; puede tomar cuatro valores: mayoritario, representación proporcional y "otros" (incluye mixtos).
- `v2psoppaut`: indicador (numérico) de grado de autonomía de partidos en la oposición.
- `v2elmulpar`: indicador (binario) de multipartidismo; puede tomar dos valores: "no/limitado" y "sí".

Usando estos datos y las funciones apropiadas en R (1.0 punto):

- Construir una tabla cruzada que cuente cuántos países con sistemas mayoritarios tienen sistemas multipartidistas.
- Construir e interpretar una gráfica sencilla que muestre la relación entre el grado de autonomía de la oposición y el nivel de democracia electoral.

### Seleccionar observaciones

Cargar a la sesión de R la base de datos que piensan utilizar en el proyecto de investigación del curso. Utilizar las funciones y operadores apropiados para seleccionar las filas (casos) potencialmente interesantes o relevantes para la investigación. Guardar este subconjunto de datos (un "*subset*") como un objeto nuevo tipo `tibble` nuevo (1.0 punto).

- Bono: Convertir todos los nombres de columna a `snake_case` (usando funciones, no a mano). Esto les ahorrará dolores de cabeza a largo plazo.
- Bono: mostrar que los valores `NA` de las variables de interés -si los hay- están codificados apropiadamente (no como `-999`, `"N/A"` o similares). Esto les ahorrará dolores de cabeza a largo plazo.

### Seleccionar variables

Usando el objeto creado en el punto anterior (el subconjunto de datos), utilizar las funciones y operadores apropiados para seleccionar las variables que tengan más sentido para su investigación. Guardar este subconjunto de datos como un objeto tipo `tibble`. Después, exportar este objeto como un archivo de datos en `"data/"`; este archivo puede ser `.rds` o `.csv` (1.0 punto).

### Medias de grupos

Usando el objeto creado en los dos puntos anteriores, estimar la media de una variable *numérica* **de interés teórico** (puede ser una variable independiente o dependiente) y comparar la media de esta variable para por lo menos dos grupos o *categorías* **de interés teórico**. Interpretar los resultados (1.0 punto).

- Bono: realizar e interpretar una prueba $t$ de Student para evaluar si estas dos medias son diferentes en términos estadísticos. Pista: la librería `infer` ofrece una función para hacerlo, pero R ya incluye una.
- Bono: realizar e interpretar una tabla cruzada de dos variables y utilizar una prueba $\chi^{2}$ para evaluar si las dos variables son independientes. Pista: la librería `infer` ofrece una función para hacerlo, pero R ya incluye una.


